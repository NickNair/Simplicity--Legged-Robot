{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing using OpenCV\n",
    "\n",
    "## -By IEEE NITK\n",
    "\n",
    "### Veiwing Images\n",
    "\n",
    "In this snippet, we load a image and we then display the same image If this works without any issues you're good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[123  29  10]\n",
      "  [149  55  36]\n",
      "  [150  53  33]\n",
      "  ...\n",
      "  [171  67  98]\n",
      "  [157  56  81]\n",
      "  [153  54  74]]\n",
      "\n",
      " [[136  42  23]\n",
      "  [151  58  37]\n",
      "  [142  45  25]\n",
      "  ...\n",
      "  [167  63  94]\n",
      "  [161  61  83]\n",
      "  [159  60  78]]\n",
      "\n",
      " [[151  58  37]\n",
      "  [156  63  42]\n",
      "  [137  40  20]\n",
      "  ...\n",
      "  [158  56  84]\n",
      "  [161  60  81]\n",
      "  [160  61  77]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[166  23  45]\n",
      "  [164  23  44]\n",
      "  [162  20  43]\n",
      "  ...\n",
      "  [134  27  23]\n",
      "  [139  30  28]\n",
      "  [141  30  28]]\n",
      "\n",
      " [[164  27  48]\n",
      "  [161  24  45]\n",
      "  [159  22  44]\n",
      "  ...\n",
      "  [139  32  28]\n",
      "  [136  25  23]\n",
      "  [138  25  23]]\n",
      "\n",
      " [[151  25  44]\n",
      "  [151  25  44]\n",
      "  [151  24  45]\n",
      "  ...\n",
      "  [140  33  26]\n",
      "  [138  25  22]\n",
      "  [142  27  24]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('First.jpeg',1)\n",
    "print(img)\n",
    "cv2.imshow('image', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion From RGB to a Grayscale Image:Â¶\n",
    "\n",
    "Here we use the formulae descirbed earlier to do the conversion Here's the formula again:\n",
    "\n",
    "### Average\n",
    "Gray = (R+G+B)/3\n",
    "\n",
    "###  Luminosity\n",
    "Gray = 0.21R + 0.72G + 0.07*B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = img[:,:,0]\n",
    "green = img[:,:,1]\n",
    "red = img[:,:,2]\n",
    "\n",
    "mean = (0.33*blue + 0.33*green + 0.33*red).astype('uint8')\n",
    "lumin = (0.07*blue + 0.72*green + 0.21*red).astype('uint8')\n",
    "\n",
    "\n",
    "cv2.imshow('mean',mean)\n",
    "#cv2.waitKey()\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow('lumin',lumin)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion from Grayscale to Binary:\n",
    "\n",
    "Here we will implement the concept of thresholding\n",
    "\n",
    "Here, the matter is straight forward.\n",
    "\n",
    "If pixel value is greater than a threshold value, it is assigned one value (may be white), else it is assigned another value (may be black).\n",
    "\n",
    "The function used is cv2.threshold.\n",
    "\n",
    "First argument is the source image, which should be a grayscale image.\n",
    "\n",
    "Second argument is the threshold value which is used to classify the pixel values.\n",
    "\n",
    "Third argument is the maxVal which represents the value to be given if pixel value is more than (sometimes less than) the threshold value.\n",
    "\n",
    "OpenCV provides different styles of thresholding and it is decided by the fourth parameter of the function.\n",
    "\n",
    "cv2.THRESH_BINARY\n",
    "\n",
    "cv2.THRESH_BINARY_INV\n",
    "\n",
    "cv2.THRESH_TRUNC\n",
    "\n",
    "cv2.THRESH_TOZERO\n",
    "\n",
    "cv2.THRESH_TOZERO_INV\n",
    "\n",
    "All values above the threshold of 127 are set high (255) , and those below are set low (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('threshold.jpg',0) #Threshold_adaptive\n",
    "ret,th1 = cv2.threshold(img,140,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('output',th1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we used a global value as threshold value. But it may not be good in all the conditions where image has different lighting conditions in different areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Threshold_adaptive.jpeg',0)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,2)       #Mean\n",
    "th3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)   #Gaussian\n",
    "cv2.imshow('out',th2)\n",
    "cv2.imshow('output',th3)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Detection of a Specific Color in an Image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('gems.jpg',1)\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "lower_color = np.array([120, 60,60 ]) \n",
    "upper_color = np.array([170, 220, 190])\n",
    "mask = cv2.inRange(hsv, lower_color, upper_color)\n",
    "out = cv2.bitwise_and(img,img,mask=mask)\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('output',out)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the image \"nowYouDont.png\" and see what is written on it..........."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]\n",
      "\n",
      " [[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]\n",
      "\n",
      " [[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]\n",
      "\n",
      " [[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]\n",
      "\n",
      " [[ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  ...\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]\n",
      "  [ 32  32 145]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('nowYouDont.png',1)\n",
    "hsv = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('original',hsv)\n",
    "print(img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 220)\n",
      "[[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('lena.jpg',0)\n",
    "print(img.shape)\n",
    "\n",
    "kernel = np.array(([1,0,0],[0,1,0],[0,0,1]),dtype=np.int) \n",
    "print(kernel)\n",
    "\n",
    "output = cv2.filter2D(img,-1,kernel)   #Convolution\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('Blur',output)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kernel = np.array(([1,0,-1],[2,0,-2],[1,0,-1]),dtype=np.int) #Sobelx (Differentiation in x direction)\n",
    "\n",
    "kernel = np.array(([1,2,1],[0,0,0],[-1,-2,-1]),dtype=np.int) #Sobely (Differentiation in y direction)\n",
    "\n",
    "kernel = np.array(([0,-1,0],[-1,5,-1],[0,-1,0]),dtype=np.int) #Sharpen\n",
    "\n",
    "kernel = np.array([0, 1, 0],[1, -4, 1],[0, 1, 0]), dtype=\"int\") #Laplacian (Double Differentiation)\n",
    "\n",
    "Try Convolution with the above kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('lena.jpg',0)\n",
    "blur = cv2.GaussianBlur(img,(5,5),0) #Here (5,5) refers to a Gaussian kernel of size 5x5 of zero variance\n",
    "\n",
    "cv2.imshow('original',img)\n",
    "cv2.imshow('Blur',blur)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Detection \n",
    "\n",
    "We will use the Sobel Operator to detect edges in an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('chessboard.jpg',0)\n",
    "\n",
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5) \n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n",
    "\n",
    "sobel_both = np.sqrt(sobelx**2 + sobely**2 )\n",
    "\n",
    "\n",
    "cv2.imshow('SobelX',sobelx)\n",
    "cv2.imshow('SobelY',sobely)\n",
    "cv2.imshow('Sobel_Both',sobel_both)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[134 147 167 ... 149 164 188]\n",
      " [147 160 179 ... 169 183 198]\n",
      " [167 179 197 ... 186 200 214]\n",
      " ...\n",
      " [149 169 186 ... 171 185 204]\n",
      " [163 183 200 ... 185 198 216]\n",
      " [187 198 214 ... 203 216 228]]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('sine2.jpg',0)\n",
    "print(img)\n",
    "\n",
    "dft = cv2.dft(np.float32(img),flags = cv2.DFT_COMPLEX_OUTPUT)\n",
    "dft_shift = np.fft.fftshift(dft)\n",
    "\n",
    "mag_spectrum = 20*np.log(cv2.magnitude(dft_shift[:,:,0],dft_shift[:,:,1]))  \n",
    "mag_spectrum = np.asarray(mag_spectrum, dtype = np.uint8)\n",
    "cv2.imshow('sine',img)\n",
    "cv2.imshow('Freq-Domain',mag_spectrum)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological Transformations\n",
    "\n",
    "Erosion and Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'erosion' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0c77819236e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdilate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Erosion'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merosion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mth1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'erosion' is not defined"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Erosion.png',0)\n",
    "cv2.imshow('Original',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret,th1 = cv2.threshold(img,140,255,cv2.THRESH_BINARY)\n",
    "\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "dilate = cv2.dilate(th1,kernel,iterations = 1)\n",
    "cv2.imshow('Erosion',erosion)\n",
    "cv2.imshow('original',th1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel1 = np.ones((5,5),np.uint8)\n",
    "erosion = cv2.erode(th1,kernel1,iterations = 1)\n",
    "cv2.imshow('Dilate',dilate)\n",
    "cv2.imshow('original',th1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the image Sun.jpg and find the position of Sun..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = cv2.imread('Sun.jpg',0)\n",
    "#img = cv2.imread('threshold.jpg',0) #Threshold_adaptive\n",
    "ret,th1 = cv2.threshold(img,245,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('output',th1)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection\n",
    "\n",
    "Here we implement the Haar Cascades to detect a face in a given image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eyes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-224bbfb1915b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mroi_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0meyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_gray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meyes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_color\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mew\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mey\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eyes' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')\n",
    "while(True):\n",
    "    im = cv.VideoCapture(0)\n",
    "    a,img=im.read()\n",
    "    gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    cv.imshow('img',img) \n",
    "    cv.waitKey()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
